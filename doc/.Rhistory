install.packages(tidytext)
install.packages('tidytext')
library(DT)
install.library('DT')
install.packages('TD')
install.packages('DT')
install.packages("stringr")
install.packages("stringr")
install.package('qdap')
install.packages('qdap')
knitr::opts_chunk$set(echo = TRUE)
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/cleaned_hm.csv'
hm_data <- read_csv(urlfile)
library(tm)
library(tidytext)
library(tidytext)
library(tidyverse)
library(DT)
hm_data <- read_csv(urlfile)
corpus <- VCorpus(VectorSource(hm_data$cleaned_hm))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
View(hm_data)
stemmed <- tm_map(corpus, stemDocument) %>%
tidy() %>%
select(text)
View(stemmed)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
data("stop_words")
word <- c("happy","ago","yesterday","lot","today","months","month",
"happier","happiest","last","week","past")
stop_words <- stop_words %>%
bind_rows(mutate(tibble(word), lexicon = "updated"))
completed <- stemmed %>%
mutate(id = row_number()) %>%
unnest_tokens(stems, text) %>%
bind_cols(dict) %>%
anti_join(stop_words, by = c("dictionary" = "word"))
completed <- completed %>%
group_by(stems) %>%
count(dictionary) %>%
mutate(word = dictionary[which.max(n)]) %>%
ungroup() %>%
select(stems, word) %>%
distinct() %>%
right_join(completed) %>%
select(-stems)
completed <- completed %>%
group_by(id) %>%
summarise(text = str_c(word, collapse = " ")) %>%
ungroup()
library(stringr)
completed <- completed %>%
group_by(id) %>%
summarise(text = str_c(word, collapse = " ")) %>%
ungroup()
hm_data <- hm_data %>%
mutate(id = row_number()) %>%
inner_join(completed)
datatable(hm_data)
View(stemmed)
View(dict)
View(stop_words)
View(stemmed)
View(stemmed)
View(stop_words)
View(stemmed)
View(dict)
View(completed)
View(dict)
View(stemmed)
View(stems)
View(stemmed)
View(dict)
sb = stemmed %>%
mutate(id = row_number())
View(sb)
sb = stemmed %>%
mutate(id = row_number()) %>%
unnest_tokens(stems, text)
View(sb)
sb = stemmed %>%
mutate(id = row_number()) %>%
unnest_tokens(stems, text) %>%
bind_cols(dict)
View(sb)
bs = stemmed %>%
mutate(id = row_number()) %>%
unnest_tokens(stems, text)
View(bs)
View(dict)
nb = tidy(corpus)
View(nb)
View(completed)
nbb = completed %>%
group_by(stems) %>%
count(dictionary)
completed <- stemmed %>%
mutate(id = row_number()) %>%
unnest_tokens(stems, text) %>%
bind_cols(dict) %>%
anti_join(stop_words, by = c("dictionary" = "word"))
View(completed)
nb = completed %>%
group_by(stems) %>%
count(dictionary)
View(nb)
nnb = nb  %>%
mutate(word = dictionary[which.max(n)])
View(nnb)
completed <- stemmed %>%
mutate(id = row_number()) %>%
unnest_tokens(stems, text) %>%
bind_cols(dict) %>%
anti_join(stop_words, by = c("dictionary" = "word"))
completed <- completed %>%
group_by(stems) %>%
count(dictionary) %>%
mutate(word = dictionary[which.max(n)]) %>%
ungroup() %>%
select(stems, word) %>%
distinct() %>%
right_join(completed) %>%
select(-stems)
completed <- completed %>%
group_by(id) %>%
summarise(text = str_c(word, collapse = " ")) %>%
ungroup()
hm_data <- hm_data %>%
mutate(id = row_number()) %>%
inner_join(completed)
View(completed)
View(hm_data)
View(completed)
View(hm_data)
getwd()
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
install.packages('wordcloud2')
install.packages('ngram')
library(wordcloud2)
library(ngram)
hm_data <- read_csv("../output/processed_moments.csv")
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data <- read_csv(urlfile)
View(demo_data)
View(hm_data)
View(demo_data)
hm_data <- hm_data %>%
inner_join(demo_data, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
library(forcats)
hm_data <- hm_data %>%
inner_join(demo_data, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
datatable(hm_data)
bag_of_words <-  hm_data %>%
unnest_tokens(word, text)
View(bag_of_words)
word_count <- bag_of_words %>%
count(word, sort = TRUE)
View(word_count)
View(hm_data)
hm_bigrams <- hm_data %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
hm_bigrams <- hm_data %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
hm_data %>%
filter(count != 1)
hm_data %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
hm_bigrams <- hm_data %>%
filter(count != 1) %>%
unnest_tokens(text, token = "ngrams", n = 2)
hm_bigrams <- hm_data %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
```{r bigram, warning=FALSE, message=FALSE}
hm_bigrams <- hm_data %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
View(bag_of_words)
View(word_count)
hm_bigrams <- hm_data %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
bigram_counts <- hm_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
View(hm_data)
hm_bigrams <- hm_data %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
hm_bigrams <- hm_data %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
install.packages("dplyr")
install.packages("dplyr")
hm_bigrams <- hm_data %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
install.packages("tidyr")
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
library(forcats)
bag_of_words <-  hm_data %>%
unnest_tokens(word, text)
word_count <- bag_of_words %>%
count(word, sort = TRUE)
hm_bigrams <- hm_data %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
View(hm_bigrams)
bigram_counts <- hm_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
View(bigram_counts)
ui <- navbarPage("What makes people happy?",
tabPanel("Overview",
titlePanel(h1("Most Frequent Occurrences",
align = "center")),
sidebarLayout(
sidebarPanel(
sliderInput(inputId = "topWordcloud",
label = "Number of terms for word cloud:",
min = 5,
max = 100,
value = 50),
br(),
br(),
checkboxInput(inputId = "topFreqB",
label = "Plot Bar Chart",
value = F),
sliderInput(inputId = "topBarchart",
label = "Number of terms for bar chart:",
min = 1,
max = 25,
value = 10),
br(),
br(),
checkboxInput(inputId = "topFreqN",
label = "Plot Network Graph",
value = F),
sliderInput(inputId = "topNetwork",
label = "Number of edges for network graph:",
min = 1,
max = 150,
value = 50)
),
mainPanel(
wordcloud2Output(outputId = "WC"),
plotOutput(outputId = "figure")
)
)
),
tabPanel("Individual Terms",
titlePanel(h1("Comparison of Proportions",
align = "center")),
sidebarLayout(
sidebarPanel(
selectInput(inputId = "attribute",
label = "Select the attribute:",
choices = c("Gender" = "gender",
"Marital Status" = "marital",
"Parenthood" = "parenthood",
"Reflection Period" = "reflection_period")
)
),
mainPanel(
plotOutput(outputId = "scatter")
)
)
),
tabPanel("Pair of Words",
titlePanel(h1("Most Frequent Bigrams",
align = "center")),
sidebarLayout(
sidebarPanel(
selectInput(inputId = "factor",
label = "Select the attribute:",
choices = c("Gender" = "gender",
"Marital Status" = "marital",
"Parenthood" = "parenthood",
"Reflection Period" = "reflection_period")
),
numericInput(inputId = "topBigrams",
label = "Number of top pairs to view:",
min = 1,
max = 25,
value = 10)
),
mainPanel(
plotOutput(outputId = "bar")
)
)
),
tabPanel("Data",
DT::dataTableOutput("table")
)
)
View(hm_data)
View(demo_data)
View(hm_data)
View(hm_bigrams)
View(hm_data)
hm_data <- read_csv("../output/processed_moments.csv")
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data <- read_csv(urlfile)
demo_data <- read_csv(urlfile)
hm_data <- hm_data %>%
inner_join(demo_data, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
View(hm_data)
nb <- hm_data %>%
inner_join(get_sentiments("AFINN"))
nb <- hm_data %>%
inner_join(get_sentiments("afinn"))
nb <- hm_data %>%
inner_join(get_sentiments(by = "afinn"))
View(demo_data)
View(hm_data)
nb <- hm_data %>%
inner_join(get_sentiments("afinn", by = original_hm))
nb <- hm_data %>%
select(original_hm) %>%
inner_join(get_sentiments("afinn"))
nb <- hm_data %>%
select(original_hm) %>%
get_sentiments("afinn")
nb <- hm_data %>%
select(original_hm) %>%
get_sentiments(lexicon = "afinn")
nb <- hm_data %>%
select(original_hm) %>%
sb = get_sentiments(lexicon = "afinn")
sb = get_sentiments(lexicon = "afinn")
View(sb)
install.packages('sentimentr')
library(sentimentr)
install.packages('textshape', type = 'source')
install.packages("devtools")
install_github("mannau/tm.plugin.sentiment")
library(devtools)
install_github("mannau/tm.plugin.sentiment")
install_github('trinker/sentimentr')
update.packages()
library(installr)
install.packages('installr')
install.packages('sentimentr')
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
install.packages(tidyverse)
install.packages('tidyverse')
install.packages('tidytext')
install.packages('DT')
install.packages('scales')
install.packages("scales")
install.packages("wordcloud2")
install.packages("grudExtra")
install.packages("ngram")
install.packages("shiny")
install.packages("forcats")
library(tidyverse)
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
install.packages("gridExtra")
library(gridExtra)
library(sentimentr)
install.packages('data.table')
library(sentimentr)
install.packages("data.table", dependencies=TRUE)
library(sentimentr)
install.packages("data.table", dependencies=TRUE)
